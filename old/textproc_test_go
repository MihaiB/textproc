
func checkTokenChannel(t *testing.T, tokCh <-chan []rune, tokens []string) {
	for _, want := range tokens {
		if gotRunes, ok := <-tokCh; !ok {
			t.Fatalf("Token channel closed early, expected %#v",
				want)
		} else if got := string(gotRunes); got != want {
			t.Fatalf("Want %#v got %#v", want, got)
		}
	}

	if gotRunes, ok := <-tokCh; ok {
		t.Fatalf("Unexpected additional token: %#v", string(gotRunes))
	}
}

func checkChannels(t *testing.T, runeCh <-chan rune, runes []rune,
	errCh <-chan error, err error) {
	checkChannel(t, runeCh, runes)
	checkErrorChannel(t, errCh, err)
}

func checkProcessor(t *testing.T, p textproc.Processor,
	inOut map[string]string) {
	for in, out := range inOut {
		dry, errCh := textproc.Read(strings.NewReader(in))
		wet := p(dry)
		checkChannels(t, wet, []rune(out), errCh, io.EOF)
	}
}

func checkTokenizer(t *testing.T, tok textproc.Tokenizer,
	inOut map[string][]string) {
	for in, out := range inOut {
		dry, errCh := textproc.Read(strings.NewReader(in))
		wet := tok(dry)
		checkTokenChannel(t, wet, out)
		checkErrorChannel(t, errCh, io.EOF)
	}
}

func TestMatchProcessorType(*testing.T) {
	for range []textproc.Processor{
		textproc.EnsureFinalLFIfNonEmpty,
		textproc.TrimLFTrailingWhiteSpace,
		textproc.TrimLeadingEmptyLFLines,
		textproc.TrimTrailingEmptyLFLines,
		textproc.SortLFLinesI,
		textproc.SortLFParagraphsI,
	} {
	}
}

func TestMatchTokenizerType(*testing.T) {
	for range []textproc.Tokenizer{
		textproc.EmitLFLineContent,
		textproc.EmitLFParagraphContent,
	} {
	}
}

func TestTrimLFTrailingWhiteSpace(t *testing.T) {
	inOut := map[string]string{
		"":                                   "",
		" @":                                 " @",
		"\nT\t\r\n\n sp  \n\tmix \tz \t\r\n": "\nT\n\n sp\n\tmix \tz\n",
		"no final LF \t":                     "no final LF",
	}
	checkProcessor(t, textproc.TrimLFTrailingWhiteSpace, inOut)
}

func TestTrimLeadingEmptyLFLines(t *testing.T) {
	inOut := map[string]string{
		"":              "",
		"\n":            "",
		"\n\n\n":        "",
		"\n\nwy-z":      "wy-z",
		"ab\nc":         "ab\nc",
		"\n\nij\n\nk\n": "ij\n\nk\n",
	}
	checkProcessor(t, textproc.TrimLeadingEmptyLFLines, inOut)
}

func TestTrimTrailingEmptyLFLines(t *testing.T) {
	inOut := map[string]string{
		"":             "",
		"\n":           "",
		"\n\n":         "",
		"\n\n\n":       "",
		"\n\n\n\r":     "\n\n\n\r",
		"\n\n\nwz":     "\n\n\nwz",
		"a\n\n\n":      "a\n",
		"\n\na\n\nb":   "\n\na\n\nb",
		"x\n\ny\n\n":   "x\n\ny\n",
		"x\n\ny\n":     "x\n\ny\n",
		"a\n\nb\n\n\n": "a\n\nb\n",
		"a\n\nbc":      "a\n\nbc",
	}
	checkProcessor(t, textproc.TrimTrailingEmptyLFLines, inOut)
}

func TestEmitLFLineContent(t *testing.T) {
	inOut := map[string][]string{
		"":         nil,
		"Î±":        {"Î±"},
		"\r\nÎ²Ã¨\n": {"\r", "Î²Ã¨"},
		"\n\nz":    {"", "", "z"},
		"Î¶\nÎ¾ a":   {"Î¶", "Î¾ a"},
	}
	checkTokenizer(t, textproc.EmitLFLineContent, inOut)
}

func TestSortLFLinesI(t *testing.T) {
	inOut := map[string]string{
		"":                       "",
		"Q\n\na\nrrr":            "\na\nQ\nrrr\n",
		"second\nfirst\nmiddle.": "first\nmiddle.\nsecond\n",
		"Bb\nbB\nBB\na\n":        "a\nBb\nbB\nBB\n",
		"bz\n\nA\n\n\nC":         "\n\n\nA\nbz\nC\n",
	}
	checkProcessor(t, textproc.SortLFLinesI, inOut)
}

func TestEmitLFParagraphContent(t *testing.T) {
	inOut := map[string][]string{
		"":                     nil,
		"a\r\nb\n \nc\n\nd":    {"a\r\nb\n \nc", "d"},
		"\n\nÎ´Ïƒ\n\n\n":         {"Î´Ïƒ"},
		"\n\nÎ´Ïƒ\n\n\n\nx\ny\n": {"Î´Ïƒ", "x\ny"},
		"Ã¸\n\nb\nc\n":          {"Ã¸", "b\nc"},
	}
	checkTokenizer(t, textproc.EmitLFParagraphContent, inOut)
}

func TestSortLFParagraphsI(t *testing.T) {
	inOut := map[string]string{
		"":                          "",
		"\n\n\n":                    "",
		"Par1":                      "Par1\n",
		"Hi\nðŸ‘½\n\nalien\n\n\nspace": "alien\n\nHi\nðŸ‘½\n\nspace\n",
		"NEON\n\nargon\n\nradon\nxenon\n\n\n\nKr\nHe\n\n": "argon\n\nKr\nHe\n\nNEON\n\nradon\nxenon\n",
	}
	checkProcessor(t, textproc.SortLFParagraphsI, inOut)
}
