
func checkTokenChannel(t *testing.T, tokCh <-chan []rune, tokens []string) {
	for _, want := range tokens {
		if gotRunes, ok := <-tokCh; !ok {
			t.Fatalf("Token channel closed early, expected %#v",
				want)
		} else if got := string(gotRunes); got != want {
			t.Fatalf("Want %#v got %#v", want, got)
		}
	}

	if gotRunes, ok := <-tokCh; ok {
		t.Fatalf("Unexpected additional token: %#v", string(gotRunes))
	}
}

func checkChannels(t *testing.T, runeCh <-chan rune, runes []rune,
	errCh <-chan error, err error) {
	checkChannel(t, runeCh, runes)
	checkErrorChannel(t, errCh, err)
}

func checkProcessor(t *testing.T, p textproc.Processor,
	inOut map[string]string) {
	for in, out := range inOut {
		dry, errCh := textproc.Read(strings.NewReader(in))
		wet := p(dry)
		checkChannels(t, wet, []rune(out), errCh, io.EOF)
	}
}

func checkTokenizer(t *testing.T, tok textproc.Tokenizer,
	inOut map[string][]string) {
	for in, out := range inOut {
		dry, errCh := textproc.Read(strings.NewReader(in))
		wet := tok(dry)
		checkTokenChannel(t, wet, out)
		checkErrorChannel(t, errCh, io.EOF)
	}
}

func TestEmitLFParagraphContent(t *testing.T) {
	inOut := map[string][]string{
		"":                     nil,
		"a\r\nb\n \nc\n\nd":    {"a\r\nb\n \nc", "d"},
		"\n\nÎ´Ïƒ\n\n\n":         {"Î´Ïƒ"},
		"\n\nÎ´Ïƒ\n\n\n\nx\ny\n": {"Î´Ïƒ", "x\ny"},
		"Ã¸\n\nb\nc\n":          {"Ã¸", "b\nc"},
	}
	checkTokenizer(t, textproc.EmitLFParagraphContent, inOut)
}

func TestSortLFParagraphsI(t *testing.T) {
	inOut := map[string]string{
		"":                          "",
		"\n\n\n":                    "",
		"Par1":                      "Par1\n",
		"Hi\nðŸ‘½\n\nalien\n\n\nspace": "alien\n\nHi\nðŸ‘½\n\nspace\n",
		"NEON\n\nargon\n\nradon\nxenon\n\n\n\nKr\nHe\n\n": "argon\n\nKr\nHe\n\nNEON\n\nradon\nxenon\n",
	}
	checkProcessor(t, textproc.SortLFParagraphsI, inOut)
}
